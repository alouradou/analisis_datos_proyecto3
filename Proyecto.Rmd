---
title: "Trabajo"
author: "Arthur"
date: "2023-05-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tarea 3 con la serie 'NDatos2000_2010'

## Imports

```{r}
library(readxl)
library(randomForest)
library(partykit)
library(rpart)

```

## Pregunta 1

### Preparaci칩n de datos

```{r}
set.seed(12345)

NDatos <- data.frame(read_excel("NDatos2000_2010.xlsx")) # 
orig_col <- colnames(NDatos)
colnames(NDatos) <- 1:ncol(NDatos)
NDatos <- NDatos[-c(23,24,25)]
NDatos[,12] <- as.numeric(NDatos[,12])

train_index <- sample(1:nrow(NDatos), nrow(NDatos) * 0.7) # cambiar aqui el split train/test
test_index <- setdiff(1:nrow(NDatos), train_index)

train_datos <- NDatos[train_index,]
test_datos <- NDatos[-train_index,]
# test_datos <- NDatos[test_index,]

```
### Evaluaci칩n de diferentes Random Forests

```{r}

ntrees = c(1000)
maxnodes = c(100, 150)
mtries = c(3)

for (ntree in ntrees) {
  for (maxnode in maxnodes) {
    for (mtry in mtries) {
      print(paste("Modeling for", as.character(ntree), ",", as.character(maxnode), ",", as.character(mtry)))
      rf_model <- randomForest(train_datos[,-19], train_datos[,19], 
                               ntree = ntree, maxnodes = maxnode, mtry = mtry, importance=TRUE)
      
      predict_rf = predict(rf_model,newdata=test_datos,type="response")
      
      error_prediccion_rf = test_datos[,19] - predict_rf
      MSE_RF=sum(error_prediccion_rf^2)/nrow(test_datos)
      print(MSE_RF)
    }
  }
}


```

Vemos en Results.txt que el modelo con la MSE la m치s baja es el 500, 200, 3 
que vamos a usar ahora.


### Elecci칩n del mejor RF (500, 200, 3)

```{r}
modelo1 = randomForest(train_datos[,c(-19,-12)],train_datos[,19],ntree=500,maxnodes=200, mtry=3, importance=TRUE)

predict1 = predict(modelo1,newdata=test_datos[,-12],type="response")

error_prediccion_1=test_datos[,19]-predict1
# View(data.frame(observed=test_datos[,19],predicted=predict1,error_prediccion_1))
MSE_RF=sum(error_prediccion_1^2)/nrow(test_datos)
print(MSE_RF)

```

```{r}
par(mfrow = c(2,1))
# Tracer les courbes d'apprentissage et de test
plot(NDatos$'19', type = "l", col = "blue", xlab = "Index", ylab = "Valeur", 
     # xlim = c(17500,18200),
     main = "Courbes d'apprentissage et de test")
# lines(seq_along(train_datos$'19'), train_datos$'19', col = "blue")
points(test_index, test_datos$'19', 
       type = "p", pch = 3, cex = 0.1,
       col = "orange")

# Tracer les courbes d'apprentissage et de test
plot(NDatos$'19', type = "l", col = "blue", xlab = "Index", ylab = "Valeur", 
     xlim = c(17500,18200),
     main = "Zoom")
# lines(seq_along(train_datos$'19'), train_datos$'19', col = "blue")
points(test_index, test_datos$'19', 
       type = "p", pch = 3, cex = 1,
       col = "orange")

```


```{r}
modelo_ctree = ctree(train_datos[,19] ~ .,data=train_datos,control=ctree_control(maxdepth=8))
varimp(modelo_ctree)

predict_ctree = predict(modelo_ctree, newdata = test_datos, type="response")
error_prediccion_ctree = test_datos[,19] - predict_ctree
# View(data.frame(observed=test_datos[,19],predicted=predict_ctree,error=error_prediccion_ctree))

MSE_CT = sum(error_prediccion_ctree^2)/nrow(test_datos)
print(MSE_CT)

```
## Modelo RPart

```{r}
modelo_rpart = rpart(train_datos[,19] ~ .,data=train_datos, control=rpart.control(cp=0.04))

predict_rpart = predict(modelo_rpart, newdata = test_datos, type = "vector")
error_prediccion_rpart = test_datos[,19] - predict_rpart

MSE_RP = sum(error_prediccion_rpart^2)/nrow(test_datos)
print(MSE_RP)

```


